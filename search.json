[{"title":"Python线程池模拟实现","url":"/archives/c07a9f32.html","content":"<Excerpt in index | 首页摘要>\nPython线程池模拟实现，模拟线程复用减少系统资源的开销。\n<!-- more -->\n<The rest of contents | 余下全文>\n\n``` python\n# !/usr/bin/env python\n# -*- coding:utf-8 -*-\n# 参考（有改动）:http://www.open-open.com/home/space-5679-do-blog-id-3247.html\n\nimport Queue\nimport threading\nimport time\nfrom threading import Lock\n\n\nclass WorkManager(object):\n    def __init__(self, work_num=1000,thread_num=2):\n        self.work_queue = Queue.Queue()\n        self.threads = []\n        self.__init_work_queue(work_num)\n        self.__init_thread_pool(thread_num)\n\n    \"\"\"\n        初始化线程\n    \"\"\"\n    def __init_thread_pool(self,thread_num):\n        for i in range(thread_num):\n            self.threads.append(Work(self.work_queue))\n\n    \"\"\"\n        初始化工作队列\n    \"\"\"\n    def __init_work_queue(self, jobs_num):\n        for i in range(jobs_num):\n            self.add_job(do_job, i)\n\n    \"\"\"\n        添加一项工作入队\n    \"\"\"\n    def add_job(self, func, *args):\n        self.work_queue.put((func, list(args)))#任务入队，Queue内部实现了同步机制\n    \"\"\"\n        检查剩余队列任务\n    \"\"\"\n    def check_queue(self):\n        return self.work_queue.qsize()\n\n    \"\"\"\n        等待所有线程运行完毕\n    \"\"\"\n    def wait_allcomplete(self):\n        for item in self.threads:\n            if item.isAlive():item.join()\n\nclass Work(threading.Thread):\n    def __init__(self, work_queue):\n        threading.Thread.__init__(self)\n        self.work_queue = work_queue\n        self.start()\n\n    def run(self):\n        #死循环，从而让创建的线程在一定条件下关闭退出\n        while True:\n            try:\n                do, args = self.work_queue.get(block=False)#任务异步出队，Queue内部实现了同步机制\n                do(args)\n                self.work_queue.task_done()#通知系统任务完成\n            except Exception,e:\n                print str(e)\n                break\n\n#具体要做的任务\ndef do_job(args):\n    time.sleep(0.1)#模拟处理时间\n    lock.acquire()\n    print threading.current_thread(), list(args)\n    lock.release()\n\nif __name__ == '__main__':\n    lock = Lock()\n    start = time.time()\n    work_manager =  WorkManager(10, 2)\n    work_manager.wait_allcomplete()\n    end = time.time()\n    print \"cost all time: %s\" % (end-start)\n    \n```","tags":["线程池"]},{"title":"Python多线程示例","url":"/archives/4a17b156.html","content":"<Excerpt in index | 首页摘要>\n基于代码示例展示Python多线程\n<!-- more -->\n<The rest of contents | 余下全文>\n\n### 单线程示例\n\n``` python\nimport time\nimport urllib2\n \ndef get_responses():\n    urls = [\n        'http://www.google.com',\n        'http://www.amazon.com',\n        'http://www.ebay.com',\n        'http://www.alibaba.com',\n        'http://www.reddit.com'\n    ]\n    start = time.time()\n    for url in urls:\n        print url\n        resp = urllib2.urlopen(url)\n        print resp.getcode()\n    print \"Elapsed time: %s\" % (time.time()-start)\n \nget_responses()\n```\n\n程序输出： \n```\nhttp://www.google.com 200 \nhttp://www.amazon.com 200 \nhttp://www.ebay.com 200 \nhttp://www.alibaba.com 200 \nhttp://www.reddit.com 200 \nElapsed time: 3.0814409256\n```\n\n解读：URL按顺序被依次串行请求，网络请求会花费较长的时间，所以CPU在等待网络请求返回时一直处于闲置状态。\n\n\n\n### 多线程示例\n\n``` python\nimport urllib2\nimport time\nfrom threading import Thread\n \nclass GetUrlThread(Thread):\n    def __init__(self, url):\n        self.url = url \n        super(GetUrlThread, self).__init__()\n \n    def run(self):\n        resp = urllib2.urlopen(self.url)\n        print self.url, resp.getcode()\n \ndef get_responses():\n    urls = [\n        'http://www.google.com', \n        'http://www.amazon.com', \n        'http://www.ebay.com', \n        'http://www.alibaba.com', \n        'http://www.reddit.com'\n    ]\n    start = time.time()\n    threads = []\n    for url in urls:\n        t = GetUrlThread(url)\n        threads.append(t)\n        t.start()\n    for t in threads:\n        t.join()\n    print \"Elapsed time: %s\" % (time.time()-start)\n \nget_responses()\n\n```\n\n程序输出：\n```\nhttp://www.reddit.com 200 \nhttp://www.google.com 200 \nhttp://www.amazon.com 200 \nhttp://www.alibaba.com 200 \nhttp://www.ebay.com 200 \nElapsed time: 0.689890861511\n```\n\n解读：通过多线程来减少CPU的等待时间，即在等待一个线程网络请求返回时，CPU可以继续处理其它线程中的请求操作。注意，在该多线程环境下，我们无法保证各请求的执行顺序。通过时间统计，可以看到在该IO密集应用中，处理性能得到了有效提升。\n\n### 多线程之线程安全\n\n``` python\nfrom threading import Lock, Thread\nlock = Lock()\nsome_var = 0\n \nclass IncrementThread(Thread):\n    def run(self):\n        #read the global variable and then increment it\n        global some_var\n        lock.acquire() # lock acquire\n        read_value = some_var\n        print \"some_var in %s is %d\" % (self.name, read_value)\n        some_var = read_value + 1\n        print \"some_var in %s after increment is %d\" % (self.name, some_var)\n        lock.release() # lock release\n \ndef use_increment_thread():\n    threads = []\n    for i in range(50):\n        t = IncrementThread()\n        threads.append(t)\n        t.start()\n    for t in threads:\n        t.join()\n    print \"After 50 modifications, some_var should have become 50\"\n    print \"After 50 modifications, some_var is %d\" % (some_var,)\n \nuse_increment_thread()\n```\n解读：通过Lock来实现全局变量的同步访问，防止由于资源竞争而导致执行结果的不确定性。\n\n### 多线程之原子操作\n\n``` python\nfrom threading import Thread, Lock\nimport time\n \nlock = Lock()\n \nclass CreateListThread(Thread):\n    def run(self):\n        self.entries = []\n        for i in range(10):\n            time.sleep(0.01)\n            self.entries.append(i)\n        lock.acquire()\n        print self.entries\n        lock.release()\n \ndef use_create_list_thread():\n    for i in range(3):\n        t = CreateListThread()\n        t.start()\n \nuse_create_list_thread()\n```\n解读：若不使用lock，运行几次会发现并没有打印出正确的结果，因为当一个线程正在打印时，CPU切换到了另一个线程，所以产生了不正确的结果。我们需要确保print self.entries是个逻辑上的原子操作，以防打印时被其他线程打断。该示例证明了一个线程不可以修改其他线程内部的变量（非全局变量）。\n\n### 多线程之threadpool\n\n``` python\nimport threadpool\nimport time\nimport urllib2\n\nurls = [\n    'http://www.google.com', \n    'http://www.amazon.com', \n    'http://www.ebay.com', \n    'http://www.alibaba.com', \n    'http://www.reddit.com'\n]\n\ndef myRequest(url):\n    resp = urllib2.urlopen(url)\n    print url, resp.getcode()\n\n\ndef timeCost(request, n):\n  print \"Elapsed time: %s\" % (time.time()-start)\n\nstart = time.time()\npool = threadpool.ThreadPool(5) # 最多可创建5线程\n#makeRequests(some_callable, list_of_args, callback)\nreqs = threadpool.makeRequests(myRequest, urls, timeCost)\n[ pool.putRequest(req) for req in reqs ]\npool.wait()\n\n```\nmakeRequests创建了要开启多线程的函数，以及函数相关参数和回调函数，其中回调函数可省略。注意，threadpool不是线程安全的。\n\n![upload successful](/images/pasted-0.png)\n\n引用链接：[理解 Python 中的多线程](https://my.oschina.net/leejun2005/blog/179265)","tags":["Python  多线程"],"categories":["Python"]},{"title":"Third","url":"/archives/e5f30f60.html","content":"** {{ title }}：** <Excerpt in index | 首页摘要>\noriginal:https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/\n<!-- more -->\n<The rest of contents | 余下全文>\n##### NameNode 高可用整体架构概述\n\n    在 Hadoop 1.0 时代，Hadoop 的两大核心组件 HDFS NameNode 和 JobTracker 都存在着单点问题，这其中以 NameNode 的单点问题尤为严重。因为 NameNode 保存了整个 HDFS 的元数据信息，一旦 NameNode 挂掉，整个 HDFS 就无法访问，同时 Hadoop 生态系统中依赖于 HDFS 的各个组件，包括 MapReduce、Hive、Pig 以及 HBase 等也都无法正常工作，并且重新启动 NameNode 和进行数据恢复的过程也会比较耗时。这些问题在给 Hadoop 的使用者带来困扰的同时，也极大地限制了 Hadoop 的使用场景，使得 Hadoop 在很长的时间内仅能用作离线存储和离线计算，无法应用到对可用性和数据一致性要求很高的在线应用场景中。\n\n    所幸的是，在 Hadoop2.0 中，HDFS NameNode 和 YARN ResourceManger(JobTracker 在 2.0 中已经被整合到 YARN ResourceManger 之中) 的单点问题都得到了解决，经过多个版本的迭代和发展，目前已经能用于生产环境。HDFS NameNode 和 YARN ResourceManger 的高可用 (High Availability，HA) 方案基本类似，两者也复用了部分代码，但是由于 HDFS NameNode 对于数据存储和数据一致性的要求比 YARN ResourceManger 高得多，所以 HDFS NameNode 的高可用实现更为复杂一些，本文从内部实现的角度对 HDFS NameNode 的高可用机制进行详细的分析。","tags":["测试，论文"],"categories":["玩转大数据"]}]